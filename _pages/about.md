---
layout: about
title: About
permalink: /
subtitle: 

profile:
  align: right
  image: grad-profile-photo.png
  image_circular: false # crops the image to make it circular

  more_info: >


news: true # includes a list of news items
selected_papers: true # includes a list of papers marked as "selected={true}"
social: true # includes social icons at the bottom of the page
---

I am a first-year CS PhD student at [UC San Diego](https://ucsd.edu/), advised by [Hao Su](https://cseweb.ucsd.edu/~haosu/) and [Henrik I. Christensen](https://hichristensen.com/), and an intern at the [Boston Dynamics AI Institute](https://rai-inst.com/). Previously, I visited [Stanford Vision and Learning Lab](https://svl.stanford.edu/), working with [Yunzhu Li](https://yunzhuli.github.io/) and [Jiajun Wu](https://jiajunwu.com/) on world modeling with multi-modal perception for robotic manipulation. I received my Bachelor’s degree in Computer Science and Statistics from the [National University of Singapore](https://nus.edu.sg/) with the highest distinction, working with [David Hsu](https://www.comp.nus.edu.sg/~dyhsu/). 

Broadly, I aim to develop principled and scalable machine learning methods for solving real-world robotic tasks. Recently, my research centers on the aspect of **embodiment** in embodied intelligence—one question being how agents can learn from and generalize across diverse physical forms. Learning from human data is a special case of this broader problem. I study these questions through both model-free and model-based approaches for task domains range from locomotion to dexterous manipulation. 

[//]: # (Recently, my research centers on cross-embodiment intelligence—one question being how agents learn from and generalize across diverse physical embodiments.)

[//]: # (I received my Bachelor’s degree in Computer Science and Statistics from the [National University of Singapore]&#40;https://nus.edu.sg/&#41; with the highest distinction, where I worked with [David Hsu]&#40;https://www.comp.nus.edu.sg/~dyhsu/&#41; on vision-based navigation at the kilometer scale using coarse maps and localization with a [Spot]&#40;https://bostondynamics.com/products/spot/&#41; robot. I also visited the [Stanford Vision and Learning Lab]&#40;https://svl.stanford.edu/&#41;, working with [Yunzhu Li]&#40;https://yunzhuli.github.io/&#41; and [Jiajun Wu]&#40;https://jiajunwu.com/&#41; on learning world models for robotic manipulation with multi-modal perception.)

[//]: # (For master’s and undergraduate students: I dedicate 30 minutes each week to connect with others, particularly those from underrepresented groups. If you are interested in discussing graduate school, research, or potential collaborations, please feel free to reach out. I am always open to engaging conversations.)

[//]: # (Link to your social media connections, too. This theme is set up to use [Font Awesome icons]&#40;https://fontawesome.com/&#41; and [Academicons]&#40;https://jpswalsh.github.io/academicons/&#41;, like the ones below. Add your Facebook, Twitter, LinkedIn, Google Scholar, or just disable all of them.)
